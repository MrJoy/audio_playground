#!/usr/bin/env ruby
# def bench_init!; @first_time = @last_time = Time.now.to_f; end

# def bench_snap!(depth = 0)
#   t = Time.now.to_f
#   elapsed = t - @last_time
#   @last_time = t
#   key = caller[depth].split(":")[0..1].join(":").split("/").last
#   key = "TOTAL" if depth > 0
#   puts "%s => %f sec (@%f)" % [key, elapsed, t]
# end

# def bench_end!
#   @last_time = @first_time
#   bench_snap!(2)

#   # From: http://eng.rightscale.com/2015/09/16/how-to-debug-ruby-memory-issues.html
#   GC.start # Start a full garbage collection
#   s = GC.stat # Take a snapshot of the gc status
#   recommended_slots = GC.stat(:heap_live_slots) * (s[:old_objects] / s[:heap_live_slots].to_f)

#   puts s.inspect
#   puts "Recommended heap slots: #{recommended_slots}"
# end

# TODO: Run update across nodes from back to front for simulation rather than
# TODO: relying on a call-chain.  This should make it easy to eliminate the
# TODO: `yield` usage and avoid associated allocations.

# TODO: Deeper memory profiling to ensure this process can run for hours.

# TODO: Pick four downlights for the dance floor, and treat them as a separate
# TODO: simulation.  Consider how spotlighting and the like will be relevant to
# TODO: them.

#   f = Fiber.new do
#     meth(1) do
#       Fiber.yield
#     end
#   end
#   meth(2) do
#     f.resume
#   end
#   f.resume
#   p Thread.current[:name]

###############################################################################
# Early Initialization/Helpers
###############################################################################
bench_init! if defined?(bench_init!)
lib = File.expand_path("../../lib", __FILE__)
$LOAD_PATH.unshift(lib) unless $LOAD_PATH.include?(lib)
require "sparkle_motion"
require "set"

SparkleMotion.init!
SparkleMotion.use_config!
# We load the following unconditionally because so much plugs into the graph
# we don't currently have a good way of decoupling things gracefully.  So all
# USE_GRAPH=0 really means is that we don't run the simulation thread.
SparkleMotion.use_graph!

# Code loading / modular behavior configuration:
USE_LIGHTS  = env_bool("USE_LIGHTS")
USE_INPUT   = env_bool("USE_INPUT")
SKIP_INPUTS = Set.new((ENV["SKIP_INPUTS"] || "").split(/\s*,\s*/).map(&:upcase))
USE_SWEEP   = env_bool("USE_SWEEP")
USE_GRAPH   = env_bool("USE_GRAPH")
SparkleMotion.use_hue!(api: true)
# SparkleMotion.use_widgets!
# SparkleMotion.use_input! if USE_INPUT

# Crufty common code:
# require "sparkle_motion/simulation/output"
# extend SparkleMotion::Simulation::Output
extend SparkleMotion::Hue::HTTP
# extend SparkleMotion::FlowControl

###############################################################################
# Profiling and Debugging
###############################################################################
LOGGER        = SparkleMotion.logger
profile_run   = ENV["PROFILE_RUN"]
PROFILE_RUN   = (profile_run != "") ? profile_run : nil
SKIP_GC       = env_bool("SKIP_GC")
DEBUG_FLAGS   = Hash[(ENV["DEBUG_NODES"] || "")
                     .split(/\s*,\s*/)
                     .map(&:upcase)
                     .map { |nn| [nn, true] }]

###############################################################################
# Shared State Setup
###############################################################################
TIME_TO_DIE = [false, :terminate]

###############################################################################
# Profiling Support
###############################################################################
def start_ruby_prof!
  return unless PROFILE_RUN == "ruby-prof"

  SparkleMotion.logger.unknown { "Enabling ruby-prof, be careful!" }
  require "ruby-prof"
  RubyProf.measure_mode = RubyProf.const_get(ENV.fetch("RUBY_PROF_MODE").upcase)
  RubyProf.start
end

def stop_ruby_prof!
  return unless PROFILE_RUN == "ruby-prof"

  result  = RubyProf.stop
  printer = RubyProf::CallTreePrinter.new(result)
  # TODO: Put this in the CWD to be more gem-friendly?
  File.open("tmp/results.html", "w") do |fh|
    printer.print(fh, min_percent: 1)
  end
end

# Class for interacting with a Hue Bridge in a coherent manner.  Runs commands in a thread, after
# coalescing/de-duping commands.
class Bridge
  attr_reader :name
  def initialize(config, &callback)
    @config   = config
    @name     = config["name"]
    @queue    = Queue.new
    @results  = SparkleMotion::Results.new(logger: SparkleMotion.logger)
    @thread   = create_thread(&callback)
  end

  def group_command!(group_id, payload, transition: nil, &callback)
    @queue << [:group, group_id, payload, transition, callback]
  end

  def light_command!(light_id, payload, transition: nil, &callback)
    @queue << [:light, light_id, payload, transition, callback]
  end

  def start!; @thread.start; end

protected

  def create_thread(&callback)
    guarded_thread(name) do
      Thread.stop
      # TODO: Maybe keep an eye on this to ensure it's not getting too large?  Shouldn't really be
      # TODO: an issue in practice, but not certain of that.
      group_commands = []
      loop do
        raw_commands = []
        raw_commands << @queue.pop until @queue.empty?

        if raw_commands.length == 0
          LOGGER.debug { "Running a frame..." }
          raw_commands += callback.call(Time.now.to_f)
        end

        group_commands += coalesce(raw_commands.select { |(kind, *)| kind == :group })
        light_commands  = coalesce(raw_commands.select { |(kind, *)| kind == :light })

        # Don't do more than *one* group request per frame to avoid overwhelming the bridge.
        # In fact, we should probably put a timeout of ~0.5-0.75 seconds before trying another one.
        #
        # Y'know, suddenly thinking a separate thread for these might be totally OK.
        group_command = group_commands.shift
        if group_command
          req = request_for(group_command)
          result = perform_once([req]) do |_request, _status, _body|
            # TODO: Count stats?
          end
          # Re-queue for later if it failed.
          # TODO: We should probably expire bad attempts at some point...
          group_commands << group_command if result.length > 0
        end

        # Don't bother with retries here -- we'll get updates on the net frame anyway.
        # TODO: Actually, to unify this with the various CLI tools, we may want to add a
        # TODO: delivery-guarantee field...
        perform_once(light_commands) do |_request, _status, _body|
          # TODO: Count stats?
        end
      end
    end
  end

  def request_for(command)
    pl  = command[2]
    cbs = command[3]
    cb  = proc { pl.merge(merge_chain(cbs.map(&:invoke))) } if cbs.length > 0
    if command[0] == :group
      NetHTTPRequest.new(@config, :update, group_id: command[1], payload: pl, &cb)
    else
      NetHTTPRequest.new(@config, :update, light_id: command[1], payload: pl, &cb)
    end
  end

  def coalesce(commands)
    group_commands_by_entity(commands).map do |target_id, cmds|
      pl  = merge_chain(cmds.map { |cmd| cmd[2] }.compact)
      cbs = cmds.map { |cmd| cmd[3] }.flatten.compact
      [cmds.first[0], target_id, pl, cbs]
    end
  end

  def group_commands_by_entity(commands)
    grouped_commands = {}
    commands.each do |cmd|
      # Making the bold assumption that we're always doing PUT requests!
      grouped_commands[cmd[1]] ||= []
      cmd[-1] = Array(cmd[-1])
      grouped_group_commands[cmd[1]] << cmd
    end
    grouped_commands
  end

  def merge_chain(chain); chain.inject({}) { |a, e| a.merge(e) }; end
end

def pre_init!
  trap("INT") do
    # TODO: Notify `Bridge` instances that it's time to die...
    TIME_TO_DIE[0] = true
    # If we hit ctrl-c, it'll show up on the terminal, mucking with log output right when we're
    # about to produce reports.  This annoys me, so I'm working around it:
    puts
  end
  Thread.abort_on_exception = true
end

# def wait_for_threads!(threads)
#   LOGGER.unknown { "Waiting for threads to finish initializing..." }
#   wait_for(threads, "sleep")
# end

# def init!
#   LOGGER.unknown { "Initializing system..." }
#   if SKIP_GC
#     LOGGER.unknown { "Disabling garbage collection!  BE CAREFUL!" }
#     GC.disable
#   end
#   start_ruby_prof!
#   # TODO: Prime any simulations here.
# end

# def wake!(threads)
#   LOGGER.unknown { "Final setup done, waking threads..." }
#   threads.each(&:run)
# end

def main
  pre_init!

#   # wait_for_threads!(threads[:all])
#   # init!(global_results)
#   # wake!(threads[:all])
#   # spin!(threads[:lights])
#   # stop!(threads)

#   # LOGGER.unknown { "Doing final shutdown..." }
#   # global_results.done! if global_results
#   # clear_board!

#   # print_results(global_results) if global_results
#   # dump_debug_data!
end

def profile!(&block)
  unless PROFILE_RUN == "memory_profiler"
    block.call
    return
  end

  LOGGER.unknown { "Enabling memory_profiler, be careful!" }
  require "memory_profiler"
  report = MemoryProfiler.report do
    block.call
    LOGGER.unknown { "Preparing MemoryProfiler report." }
  end
  LOGGER.unknown { "Dumping MemoryProfiler report." }
  # TODO: Dump this to a file...
  report.pretty_print
end

###############################################################################
# Launcher
###############################################################################
profile! do
  bench_end! if defined?(bench_end!)
  main
end

exit 127 if TIME_TO_DIE[1] == :restart
