#!/usr/bin/env ruby
# def bench_init!; @first_time = @last_time = Time.now.to_f; end

# def bench_snap!(depth = 0)
#   t = Time.now.to_f
#   elapsed = t - @last_time
#   @last_time = t
#   key = caller[depth].split(":")[0..1].join(":").split("/").last
#   key = "TOTAL" if depth > 0
#   puts "%s => %f sec (@%f)" % [key, elapsed, t]
# end

# def bench_end!
#   @last_time = @first_time
#   bench_snap!(2)

#   # From: http://eng.rightscale.com/2015/09/16/how-to-debug-ruby-memory-issues.html
#   GC.start # Start a full garbage collection
#   s = GC.stat # Take a snapshot of the gc status
#   recommended_slots = GC.stat(:heap_live_slots) * (s[:old_objects] / s[:heap_live_slots].to_f)

#   puts s.inspect
#   puts "Recommended heap slots: #{recommended_slots}"
# end

# TODO: Run update across nodes from back to front for simulation rather than
# TODO: relying on a call-chain.  This should make it easy to eliminate the
# TODO: `yield` usage and avoid associated allocations.

# TODO: Deeper memory profiling to ensure this process can run for hours.

# TODO: Pick four downlights for the dance floor, and treat them as a separate
# TODO: simulation.  Consider how spotlighting and the like will be relevant to
# TODO: them.

#   f = Fiber.new do
#     meth(1) do
#       Fiber.yield
#     end
#   end
#   meth(2) do
#     f.resume
#   end
#   f.resume
#   p Thread.current[:name]

###############################################################################
# Early Initialization/Helpers
###############################################################################
bench_init! if defined?(bench_init!)
lib = File.expand_path("../../lib", __FILE__)
$LOAD_PATH.unshift(lib) unless $LOAD_PATH.include?(lib)
require "sparkle_motion"
require "set"

SparkleMotion.init!
# We load the following unconditionally because so much plugs into the graph
# we don't currently have a good way of decoupling things gracefully.  So all
# USE_GRAPH=0 really means is that we don't run the simulation thread.
SparkleMotion.use_graph!

# Code loading / modular behavior configuration:
USE_LIGHTS  = env_bool("USE_LIGHTS")
USE_INPUT   = env_bool("USE_INPUT")
SKIP_INPUTS = Set.new((ENV["SKIP_INPUTS"] || "").split(/\s*,\s*/).map(&:upcase))
USE_SWEEP   = env_bool("USE_SWEEP")
USE_GRAPH   = env_bool("USE_GRAPH")
SparkleMotion.use_hue!(api: true)
# SparkleMotion.use_widgets!
# SparkleMotion.use_input! if USE_INPUT

# Crufty common code:
# require "sparkle_motion/simulation/output"
# extend SparkleMotion::Simulation::Output
extend SparkleMotion::Hue::HTTP
# extend SparkleMotion::FlowControl

###############################################################################
# Profiling and Debugging
###############################################################################
LOGGER        = SparkleMotion.logger
profile_run   = ENV["PROFILE_RUN"]
PROFILE_RUN   = (profile_run != "") ? profile_run : nil
SKIP_GC       = env_bool("SKIP_GC")
DEBUG_FLAGS   = Hash[(ENV["DEBUG_NODES"] || "")
                     .split(/\s*,\s*/)
                     .map(&:upcase)
                     .map { |nn| [nn, true] }]

###############################################################################
# Shared State Setup
###############################################################################
PENDING_COMMANDS = Hash[CONFIG["bridges"].map { |bridge| [bridge["name"], Queue.new] }]

###############################################################################
# Profiling Support
###############################################################################
def start_ruby_prof!
  return unless PROFILE_RUN == "ruby-prof"

  SparkleMotion.logger.unknown { "Enabling ruby-prof, be careful!" }
  require "ruby-prof"
  RubyProf.measure_mode = RubyProf.const_get(ENV.fetch("RUBY_PROF_MODE").upcase)
  RubyProf.start
end

def stop_ruby_prof!
  return unless PROFILE_RUN == "ruby-prof"

  result  = RubyProf.stop
  printer = RubyProf::CallTreePrinter.new(result)
  File.open("tmp/results.html", "w") do |fh|
    printer.print(fh, min_percent: 1)
  end
end

###############################################################################
###############################################################################
class Bridge
  attr_reader :name
  def initialize(config, frame_duration, &callback)
    @config = config
    @name   = config["name"]
    @queue  = Queue.new
    @thread = guarded_thread(name) do
      Thread.stop
      # last_frame = 0.0
      group_commands = []
      loop do
        raw_commands = []
        raw_commands << @queue.pop until @queue.empty?

        if raw_commands.length == 0
          LOGGER.debug { "Running a frame..." }
          raw_commands += callback.call(Time.now.to_f)
        end

        LOGGER.debug { "Processing #{raw_commands.length} pending commands." }
        group_commands += commands.select { |(kind, *)| kind == :group }
                          # .map do |(_kind, target_id, payload, cmd_callback)|
                          #   group_update(@bridge, target_id, payload: payload, &cmd_callback)
                          # end
        light_commands  = commands.select { |(kind, *)| kind == :light }
                          # .map do |(_kind, target_id, payload, cmd_callback)|
                          #   light_update(@bridge, target_id, payload: payload, &cmd_callback)
                          # end

        grouped_group_commands = {}
        group_commands.each do |cmd|
          # Making the bold assumption that we're doing PUT requests!
          grouped_group_commands[cmd[1]] ||= []
          cmd[-1] = Array(cmd[-1])
          grouped_group_commands[cmd[1]] << cmd
        end
        # TODO: This could result in a really deeply nested callback chain.  Make Request support
        # TODO: a list of callbacks and we can avoid that.
        group_commands = grouped_group_commands.map do |group_id, cmds|
          pl  = merge_chain(cmds.map { |cmd| cmd[2] }.compact)
          cbs = cmds.map { |cmd| cmd[3] }.flatten.compact
          [:group, group_id, pl, cbs]
        end
        # TODO: Coalesce/de-dup light commands!

        # Don't do more than *one* group request per frame to avoid overwhelming the bridge.
        # In fact, we should probably put a timeout of ~0.5-0.75 seconds before trying another one.
        #
        # Alternatively, maybe we just wanna break it up into per-light requests, and fold those in
        # with everything else?
        group_command = group_commands.shift
        if group_command
          pl  = group_command[2]
          cbs = group_command[3]
          cb  = proc { pl.merge(merge_chain(cbs.map(&:invoke))) } if cbs.length > 0
          req = Request.new(req.bridge, req.action, group_id: group_id, payload: pl, &cb)
          result = perform_once([req]) do |_request, _status, _body|
            # TODO: Count stats?
          end
          # Re-queue for later if it failed.
          # TODO: We should probably expire bad attempts at some point...
          group_commands << group_command if result.length > 0
        end

        # Don't bother with retries here -- we'll get updates on the net frame anyway.
        perform_once(light_requests) do |_request, _status, _body|
          # TODO: Count stats?
        end
      end
    end
  end

  def group_command!(group_id, payload, transition: nil, &callback)
    @queue << [:group, group_id, payload, transition, callback]
  end

  def light_command!(light_id, payload, transition: nil, &callback)
    @queue << [:light, light_id, payload, transition, callback]
  end

  def start!; @thread.start; end

protected

  def merge_chain(chain); chain.inject({}) { |x, a| a.merge(x) }; end
end

# def launch_sweep_thread!(config, hues, sweep_len, sweep_wait)
#   guarded_thread("Sweeper") do
#     Thread.stop

#     loop do
#       before_time = Time.now.to_f
#       idx         = ((before_time / sweep_wait) % hues.length).floor
#       # TODO: Recycle this hash?
#       add_group_command!(config, with_transition_time(sweep_len, "hue" => hues[idx]))

#       elapsed = Time.now.to_f - before_time
#       sleep sweep_wait - elapsed if elapsed < sweep_wait
#     end
#   end
# end

# def launch_sweep_threads!(sweep_cfg)
#   return [] unless USE_LIGHTS && USE_SWEEP
#   CONFIG["bridges"].map do |(name, config)|
#     hues, sweep_len, sweep_wait = sweep_params(sweep_cfg[name])

#     validate_sweep_timings!(name, sweep_len, sweep_wait)

#     launch_sweep_thread!(config, hues, sweep_len, sweep_wait)
#   end
# end

# def sweep_params(config)
#   [config["values"],
#    config["transition"],
#    config["wait"]]
# end

# def validate_sweep_timings!(name, len, wait)
#   LOGGER.warn { "Sweep[#{name}]: Wait should be at least as long as transition!" } if wait < len
#   LOGGER.warn { "Sweep[#{name}]: Wait should be at least 1 second!" } if wait < 1.0
# end

# def launch_dummy_light_threads!
#   threads = []
#   threads << guarded_thread("Dummy Thread") do
#     Thread.stop
#     if ITERATIONS > 0
#       sleep 5 * ITERATIONS
#       TIME_TO_DIE[0] = true
#     else
#       sleep 0.5 until TIME_TO_DIE[0]
#     end
#   end
#   threads
# end

# def light_req(idx, lid, transition, config, stats, debug)
#   url = light_update_url(config, lid)
#   SparkleMotion::Hue::LazyRequestConfig.new(LOGGER, config, url, stats, debug: debug) do
#     # TODO: Recycle this hash?
#     data = { "bri" => (FINAL_RESULT[idx] * 255).round }
#     with_transition_time(transition, data)
#   end
# end

def launch_light_threads!(cfg, global_results, debug)
  threads = []
  return launch_dummy_light_threads! unless USE_LIGHTS

  transition  = cfg["transition"]
  threads    += LIGHTS_FOR_THREADS.bridges.map do |(bridge_name, config)|
    guarded_thread(bridge_name) do
      lights    = LIGHTS_FOR_THREADS.lights[bridge_name]
      stats     = SparkleMotion::Results.new(logger: LOGGER) if defined?(SparkleMotion::Results)
      iterator  = (ITERATIONS > 0) ? ITERATIONS.times : loop

      LOGGER.unknown do
        light_list = lights.map(&:first).join(", ")
        "#{bridge_name}: Thread set to handle #{lights.count} lights (#{light_list})."
      end

      Thread.stop

      requests = lights.map { |(idx, lid)| light_req(idx, lid, transition, config, stats, debug) }

      iterator.each do
        Curl::Multi.http(requests.dup, SparkleMotion::Hue::HTTP::MULTI_OPTIONS) do
        end

        global_results.add_from(stats) if global_results
        stats.clear! if stats
        sleep 0.1
      end
    end
  end

  threads << guarded_thread("Command Queue") do
    Thread.stop
    loop do
      sleep 0.05 while PENDING_COMMANDS.empty?

      # TODO: Gather stats about success/failure...
      # results     = SparkleMotion::Results.new(logger: LOGGER)
      # global_results.add_from(results)
      # results.clear!

      requests = []
      requests << PENDING_COMMANDS.pop until PENDING_COMMANDS.empty?
      next if requests.length == 0
      LOGGER.debug { "Processing #{requests.length} pending commands." }
      Curl::Multi.http(requests, SparkleMotion::Hue::HTTP::MULTI_OPTIONS) do |easy|
        rc    = easy.response_code
        body  = easy.body
        next if rc >= 200 && rc < 400 && body !~ /error/
        LOGGER.warn { "Problem processing command: #{easy.url} => #{rc}; #{body}" }
      end
    end
  end
end

def launch_all_threads!(sim_cfg, global_results)
  tmp = { input:  launch_input_threads!.compact,
          graph:  [launch_graph_thread!].compact,
          sweep:  launch_sweep_threads!(sim_cfg["sweep"]).compact,
          lights: launch_light_threads!(sim_cfg["output"], global_results, DEBUG_FLAGS["OUTPUT"]) }
  tmp[:all] = tmp.values.flatten.compact
  tmp
end

def pre_init!
  trap("INT") do
    TIME_TO_DIE[0] = true
    # If we hit ctrl-c, it'll show up on the terminal, mucking with log output right when we're
    # about to produce reports.  This annoys me, so I'm working around it:
    puts
  end
  Thread.abort_on_exception = true
end

def nodes_under_debug
  NODES.select { |name, _node| DEBUG_FLAGS[name] }
end

def debugging?
  nodes_under_debug.length > 0 || DEBUG_FLAGS["OUTPUT"] || PROFILE_RUN
end

def wait_for_threads!(threads)
  LOGGER.unknown { "Waiting for threads to finish initializing..." }
  wait_for(threads, "sleep")
end

def init!(global_results)
  LOGGER.unknown { "Initializing system..." }
  if SKIP_GC
    LOGGER.unknown { "Disabling garbage collection!  BE CAREFUL!" }
    GC.disable
  end
  global_results.begin! if global_results
  start_ruby_prof!
  FINAL_RESULT.update(Time.now.to_f)
end

def wake!(threads)
  LOGGER.unknown { "Final setup done, waking threads..." }
  threads.each(&:run)
end

def spin!(threads)
  LOGGER.unknown { "Waiting for the world to end..." }
  loop do
    # Someone hit the exit button:
    break if TIME_TO_DIE[0]
    # We went through and did `ITERATIONS` update loops over the lights:
    # ... the `- 1` is for the command queue thread!
    unfinished = (threads.length - threads.count { |th| th.status == false }) - 1
    break if USE_LIGHTS && unfinished == 0
    sleep 0.25
  end
end

def stop!(threads)
  LOGGER.unknown { "Stopping threads..." }
  %i(lights sweep graph input).each do |thread_group|
    threads[thread_group].each(&:terminate)
  end
end

def main
  pre_init!

  announce_iteration_config(ITERATIONS)

  global_results  = SparkleMotion::Results.new(logger: LOGGER) if defined?(SparkleMotion::Results)
  threads         = launch_all_threads!(CONFIG["simulation"], global_results)

  wait_for_threads!(threads[:all])
  init!(global_results)
  wake!(threads[:all])
  spin!(threads[:lights])
  stop!(threads)

  LOGGER.unknown { "Doing final shutdown..." }
  global_results.done! if global_results
  clear_board!

  print_results(global_results) if global_results
  dump_debug_data!
end

def profile!(&block)
  unless PROFILE_RUN == "memory_profiler"
    block.call
    return
  end

  LOGGER.unknown { "Enabling memory_profiler, be careful!" }
  require "memory_profiler"
  report = MemoryProfiler.report do
    block.call
    LOGGER.unknown { "Preparing MemoryProfiler report." }
  end
  LOGGER.unknown { "Dumping MemoryProfiler report." }
  # TODO: Dump this to a file...
  report.pretty_print
end

###############################################################################
# Launcher
###############################################################################
profile! do
  bench_end! if defined?(bench_end!)
  main
end

exit 127 if TIME_TO_DIE[1] == :restart
